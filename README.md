# üè• Healthcare AI Dashboard - Multi-Model Predictive Analytics System

<div align="center">

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-FF4B4B.svg)](https://streamlit.io/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.13+-FF6F00.svg)](https://www.tensorflow.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

**An end-to-end healthcare analytics platform leveraging 7 AI models across 4 data modalities**

[Features](#-key-features) ‚Ä¢ [Installation](#-installation) ‚Ä¢ [Usage](#-usage) ‚Ä¢ [Architecture](#-system-architecture) ‚Ä¢ [Results](#-model-performance)

</div>

---

## üìã Table of Contents
- [Problem Statement](#-problem-statement)
- [Key Features](#-key-features)
- [Dataset Overview](#-dataset-overview)
- [System Architecture](#-system-architecture)
- [AI Models Implemented](#-ai-models-implemented)
- [Why This Approach](#-why-this-approach)
- [Installation](#-installation)
- [Usage](#-usage)
- [Folder Structure](#-folder-structure)
- [Model Performance](#-model-performance)
- [Limitations & Next Steps](#-limitations--next-steps)
- [Technologies Used](#-technologies-used)
- [Contributing](#-contributing)
- [License](#-license)

---

## üéØ Problem Statement

Healthcare systems face critical challenges in:

1. **Resource Optimization:** Hospitals struggle to predict patient readmissions and length of stay, leading to inefficient bed management and staff allocation
2. **Early Intervention:** Delayed identification of high-risk patients results in preventable complications and increased mortality
3. **Diagnostic Accuracy:** Manual chest X-ray analysis is time-consuming and prone to human error, especially for pneumonia detection
4. **Patient Understanding:** Limited insights into patient segmentation and behavioral patterns hinder personalized care
5. **Quality Monitoring:** Difficulty in analyzing large volumes of patient feedback to identify systemic issues

### Our Solution
A **unified AI-powered dashboard** that combines:
- üìä **Tabular ML models** for risk stratification and stay prediction
- üß† **Deep learning** for medical imaging and sentiment analysis
- üìà **Unsupervised learning** for patient segmentation
- üîç **Pattern mining** for clinical association discovery

This enables healthcare providers to make **data-driven decisions** that improve patient outcomes while optimizing resource utilization.

---

## ‚ú® Key Features

### üîÆ Predictive Analytics
- **Readmission Risk Prediction:** Identify patients at high risk of 30-day readmission (XGBoost)
- **Length of Stay Forecasting:** Predict hospitalization duration for capacity planning (XGBoost Regressor)
- **ICU Risk Monitoring:** Real-time risk assessment using vital signs time-series (LSTM)

### üñºÔ∏è Medical Imaging
- **Pneumonia Detection:** Automated chest X-ray analysis with 94% accuracy (CNN ResNet50)
- **Visual Explanations:** Grad-CAM heatmaps showing model attention regions

### üí¨ Natural Language Processing
- **Sentiment Analysis:** Patient feedback classification using fine-tuned BERT (DistilBERT)
- **Dual-Score Display:** Both positive and negative sentiment probabilities

### üìä Pattern Discovery
- **Patient Segmentation:** KMeans clustering to identify distinct patient cohorts
- **Association Rule Mining:** Discover clinical patterns (e.g., BMI + Hypertension ‚Üí Diabetes Risk)

### üé® Interactive Dashboard
- **Multi-Dataset Homepage:** Visualize 4 datasets with 12+ interactive charts
- **Batch Prediction:** Upload CSV files for bulk patient analysis
- **Real-Time Predictions:** Instant results for individual patient data
- **Color-Coded Navigation:** 7 unique themes for easy model distinction

---

## üìä Dataset Overview

### 1. Diabetic Patient Records
- **Source:** UCI Machine Learning Repository (modified)
- **Size:** 101,766 hospital admissions
- **Features:** 50 variables including demographics, diagnoses, medications, lab results
- **Target Variables:** 
  - Readmission status (binary classification)
  - Length of stay (regression: 1-14 days)
- **Use Cases:** Readmission prediction, LOS forecasting, clustering, association rules

### 2. Vital Signs Time-Series
- **Source:** ICU monitoring data (2024)
- **Size:** 10,000+ patient records with temporal measurements
- **Features:** Heart rate, respiratory rate, blood pressure, temperature, SpO2, derived metrics (HRV, MAP, BMI)
- **Temporal Resolution:** 10-minute intervals over 24-48 hour periods
- **Use Cases:** LSTM-based ICU risk prediction

### 3. Patient Feedback (Text)
- **Source:** Hospital survey data
- **Size:** 5,000+ patient comments
- **Features:** Free-text feedback, sentiment labels (0=Negative, 1=Positive)
- **Preprocessing:** Text cleaning, BERT tokenization (max 128 tokens)
- **Use Cases:** Sentiment classification for quality monitoring

### 4. Chest X-Ray Images
- **Source:** PneumoniaMNIST (MedMNIST v2)
- **Size:** 8,136 grayscale images (28√ó28 pixels)
- **Distribution:** 
  - Training: 6,988 images (52.5% pneumonia, 47.5% normal)
  - Validation: 524 images
  - Test: 624 images
- **Balance Ratio:** 1:0.90 (Pneumonia:Normal) - Near-perfect balance
- **Use Cases:** Binary pneumonia detection

---

## üèóÔ∏è System Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      STREAMLIT DASHBOARD                         ‚îÇ
‚îÇ  (Multi-page app with color-coded navigation & batch analysis)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ         DATA PREPROCESSING LAYER             ‚îÇ
        ‚îÇ  (Modular pipelines for each data type)      ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚ñº              ‚ñº              ‚ñº              ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ Tabular  ‚îÇ   ‚îÇ   Time   ‚îÇ   ‚îÇ   Text   ‚îÇ   ‚îÇ  Image   ‚îÇ
        ‚îÇ   Data   ‚îÇ   ‚îÇ  Series  ‚îÇ   ‚îÇ   Data   ‚îÇ   ‚îÇ   Data   ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚ñº              ‚ñº              ‚ñº              ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ Encoding ‚îÇ   ‚îÇ Sequence ‚îÇ   ‚îÇ   BERT   ‚îÇ   ‚îÇ   Image  ‚îÇ
        ‚îÇ Scaling  ‚îÇ   ‚îÇ Creation ‚îÇ   ‚îÇTokenizer ‚îÇ   ‚îÇ Normalize‚îÇ
        ‚îÇImputation‚îÇ   ‚îÇDerivation‚îÇ   ‚îÇ Cleaning ‚îÇ   ‚îÇAugment   ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚ñº              ‚ñº              ‚ñº              ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ                  AI MODEL LAYER                          ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ  XGBoost    ‚îÇ   XGBoost   ‚îÇ  KMeans  ‚îÇ   Apriori       ‚îÇ
    ‚îÇ Classifier  ‚îÇ  Regressor  ‚îÇClustering‚îÇ Association     ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ     LSTM        ‚îÇ    DistilBERT    ‚îÇ  ResNet50 CNN     ‚îÇ
    ‚îÇ  Time-Series    ‚îÇ   Sentiment NLP  ‚îÇ  Image Classify   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ         PREDICTION & VISUALIZATION          ‚îÇ
        ‚îÇ  (Interactive charts, metrics, batch CSV)   ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Data Flow
1. **Raw Data Ingestion:** 4 diverse data sources (CSV, NPZ files)
2. **Modular Preprocessing:** Separate pipelines optimized per data type
3. **Model Training:** 7 specialized models with hyperparameter tuning
4. **Saved Artifacts:** Trained models, scalers, encoders stored in `Trained_Models/`
5. **Dashboard Loading:** Models loaded once via `@st.cache_resource`
6. **Real-Time Inference:** User inputs ‚Üí Preprocessing ‚Üí Prediction ‚Üí Visualization

---

## ü§ñ AI Models Implemented

### 1. Readmission Risk Prediction (Classification)
**Algorithm:** XGBoost Classifier  
**Purpose:** Predict 30-day hospital readmission probability  
**Input Features:** 20 selected features (demographics, diagnoses, medications)  
**Output:** Binary (Readmitted/Not Readmitted) + probability score  
**Technique:** SMOTE for class imbalance, `scale_pos_weight` tuning  
**Metrics:** Accuracy 67%, Precision 0.35, Recall 0.68, F1 0.46

### 2. Length of Stay Prediction (Regression)
**Algorithm:** XGBoost Regressor  
**Purpose:** Forecast hospitalization duration (1-14 days)  
**Input Features:** Vital signs, diagnosis codes, procedure counts  
**Output:** Continuous (predicted days)  
**Technique:** Grid search for optimal hyperparameters  
**Metrics:** MAE 1.05 days, RMSE 1.51 days, R¬≤ 0.78

### 3. Patient Segmentation (Clustering)
**Algorithm:** KMeans (k=4)  
**Purpose:** Group patients into cohorts for targeted interventions  
**Input Features:** 15 normalized health indicators  
**Output:** Cluster assignments (0-3)  
**Technique:** Elbow method + Silhouette score for optimal k  
**Interpretation:** Clusters represent severity levels (low-risk to critical)

### 4. Medical Association Rules (Pattern Mining)
**Algorithm:** Apriori + Association Rules  
**Purpose:** Discover co-occurrence patterns in clinical data  
**Input Features:** Categorical bins (age groups, BMI categories, diagnoses)  
**Output:** Rules with confidence and lift scores  
**Example Rule:** `{BMI:Obese, Age:60+} ‚Üí {Diabetes:Yes}` (confidence 0.85)

### 5. ICU Risk Prediction (Time-Series)
**Algorithm:** LSTM Recurrent Neural Network  
**Purpose:** Real-time risk assessment from vital sign sequences  
**Input Features:** 10-timestep windows of 6 vital signs  
**Output:** Risk category (Low/Medium/High)  
**Architecture:** 2 LSTM layers (128, 64 units) + Dropout 0.3  
**Metrics:** Accuracy 89%, AUC-ROC 0.93

### 6. Sentiment Analysis (NLP)
**Algorithm:** DistilBERT (Fine-tuned)  
**Purpose:** Classify patient feedback sentiment  
**Input Features:** Text comments (max 128 tokens)  
**Output:** Binary (Positive/Negative) + dual probability scores  
**Training:** 5 epochs, learning rate 2e-5, batch size 16  
**Metrics:** Accuracy 92%, F1 0.91

### 7. Pneumonia Detection (Computer Vision)
**Algorithm:** ResNet50 CNN (Transfer Learning)  
**Purpose:** Automated chest X-ray diagnosis  
**Input Features:** 28√ó28 grayscale images (resized to 224√ó224)  
**Output:** Binary (Pneumonia/Normal) + confidence score  
**Training:** Pre-trained ImageNet weights, fine-tuned last 10 layers  
**Metrics:** Accuracy 94%, Sensitivity 0.96, Specificity 0.92

---

## üí° Why This Approach?

### 1. Multi-Modal Data Strategy
**Decision:** Use 4 different data types (tabular, time-series, text, images)  
**Rationale:** Healthcare data is inherently diverse. A single model type cannot address all clinical needs. By combining:
- **Tabular ML** for structured health records
- **Deep Learning** for unstructured data (text, images)
- **Time-series models** for temporal vital signs
- **Unsupervised learning** for pattern discovery

We create a **comprehensive analytics ecosystem** rather than siloed solutions.

### 2. Model Selection Justification

#### Why XGBoost for Tabular Data?
- ‚úÖ Handles mixed data types (numerical + categorical) natively
- ‚úÖ Built-in regularization prevents overfitting (diabetic dataset has 50 features)
- ‚úÖ `scale_pos_weight` parameter addresses 11% readmission imbalance
- ‚úÖ Feature importance scores aid clinical interpretability
- ‚ùå Alternative: Random Forest (tested, lower accuracy by 5%)

#### Why LSTM for Vital Signs?
- ‚úÖ Captures temporal dependencies in sequential measurements
- ‚úÖ Learns patterns across time (e.g., gradual deterioration vs sudden spikes)
- ‚úÖ Bidirectional architecture considers past and future context
- ‚ùå Alternative: 1D CNN (tested, missed long-term dependencies)

#### Why BERT for Sentiment?
- ‚úÖ Pre-trained on massive text corpus (strong transfer learning)
- ‚úÖ Contextual embeddings understand nuanced medical language
- ‚úÖ DistilBERT variant reduces inference time by 60% vs full BERT
- ‚ùå Alternative: TF-IDF + Logistic Regression (14% lower accuracy)

#### Why ResNet50 for X-Rays?
- ‚úÖ Skip connections prevent vanishing gradients (50 layers deep)
- ‚úÖ Transfer learning from ImageNet provides robust feature extraction
- ‚úÖ Global Average Pooling reduces parameters, prevents overfitting
- ‚ùå Alternative: VGG16 (slower inference, more parameters)

### 3. Modular Preprocessing Design
**Decision:** Separate preprocessing notebooks per data type  
**Rationale:**
- **Tabular:** preprocessing_version_1.ipynb serves 4 models (Readmission, LOS, Clustering, Association)
- **Time-series:** Preprocessing.ipynb handles sequence creation for LSTM
- **Text:** BERT-specific tokenization in dedicated notebook
- **Images:** CNN preprocessing with augmentation

**Benefits:**
- üîÑ Reusability: One preprocessing feeds multiple models (avoid redundancy)
- üõ†Ô∏è Maintainability: Update one data type without affecting others
- üéØ Specialization: Each pipeline optimized for its data characteristics

### 4. Dashboard Architecture
**Decision:** Streamlit multi-page app with `@st.cache_resource`  
**Rationale:**
- ‚úÖ Faster than Flask for prototyping (no need for HTML/CSS/JS)
- ‚úÖ Built-in caching prevents reloading 7 models on every interaction
- ‚úÖ Interactive widgets (sliders, file uploads) with zero JavaScript
- ‚úÖ Easy deployment (one command: `streamlit run App.py`)

### 5. Batch Prediction Feature
**Decision:** Allow CSV upload for bulk analysis  
**Rationale:**
- Hospitals need to **score entire patient populations**, not just individuals
- Enables **proactive outreach** (e.g., contact all high-risk readmission patients)
- Supports **A/B testing** of interventions on different patient cohorts

---

## üöÄ Installation

### Prerequisites
- Python 3.10 or higher
- pip (Python package manager)
- 8GB+ RAM (for deep learning models)
- Windows/Linux/macOS

### Step 1: Clone Repository
```bash
git clone https://github.com/yourusername/healthcare-ai-dashboard.git
cd healthcare-ai-dashboard
```

### Step 2: Create Virtual Environment (Recommended)
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/macOS
python3 -m venv venv
source venv/bin/activate
```

### Step 3: Install Dependencies
```bash
pip install -r requirements.txt
```

**Required Packages:**
```
streamlit==1.28.0
pandas==2.0.3
numpy==1.24.3
scikit-learn==1.3.0
xgboost==2.0.0
tensorflow==2.13.0
transformers==4.33.0
torch==2.0.1
plotly==5.17.0
mlxtend==0.22.0
Pillow==10.0.0
```

### Step 4: Download Datasets
Place the following files in the project root directory:
- `diabetic_data_cleaned.csv`
- `cleaned_vital_dataset.csv`
- `cleaned_feedback_dataset.csv`
- `pneumoniamnist_balanced.npz`

*(Dataset download links provided in [DATASET_SOURCES.md](DATASET_SOURCES.md))*

### Step 5: Verify Installation
```bash
python -c "import streamlit, xgboost, tensorflow, transformers; print('All dependencies installed successfully!')"
```

---

## üìñ Usage

### Running the Dashboard

#### Option 1: Full Dashboard (All 7 Models)
```bash
cd notebooks/Dashboard
streamlit run App.py
```
**Access:** Open browser to `http://localhost:8501`

#### Option 2: Individual Model Pages
```bash
# Readmission prediction only
streamlit run notebooks/Dashboard/pages/1_readmission_model.py

# Length of stay prediction
streamlit run notebooks/Dashboard/pages/2_los_prediction.py

# And so on...
```

### Using the Dashboard

#### 1. Homepage (Multi-Dataset Overview)
- View statistics for all 4 datasets
- Explore gender distribution, admission types, age ranges
- Check data quality metrics (balance ratios, missing values)

#### 2. Readmission Risk Prediction
- **Single Prediction:** Enter patient details manually
- **Batch Prediction:** Upload CSV with columns: `age`, `time_in_hospital`, `num_lab_procedures`, etc.
- **Output:** Risk probability + classification (Readmitted/Not Readmitted)

#### 3. Length of Stay Forecasting
- **Input:** Vital signs, diagnosis codes, procedure counts
- **Output:** Predicted days + confidence interval
- **Batch Mode:** Process entire patient cohort at once

#### 4. Patient Clustering
- **Input:** Health indicators (15 features)
- **Output:** Cluster assignment (0-3) + centroid characteristics
- **Visualization:** 2D PCA plot showing cluster separation

#### 5. Association Rules
- **Input:** Categorical patient data
- **Output:** Top rules ranked by confidence and lift
- **Example:** `{Metformin:Yes, Age:>60} ‚Üí {Insulin:Yes}` (confidence 0.78)

#### 6. X-Ray Diagnostics
- **Input:** Upload chest X-ray image (JPG, PNG)
- **Output:** Pneumonia probability + Grad-CAM heatmap
- **Interpretation:** Red regions indicate pneumonia-suspicious areas

#### 7. Sentiment Analysis
- **Input:** Patient feedback text (up to 500 characters)
- **Output:** Sentiment (Positive/Negative) + dual scores
- **Examples:** Pre-loaded examples for quick testing

#### 8. LSTM Risk Prediction
- **Input:** Time-series vital signs (10 timesteps)
- **Output:** Risk category (Low/Medium/High) + probability
- **Use Case:** ICU patient monitoring

### Example Workflows

#### Workflow 1: Daily Readmission Screening
```
1. Export today's admissions from EHR ‚Üí CSV
2. Upload to "Readmission Model" batch prediction
3. Download results with risk scores
4. Flag patients with >50% readmission probability
5. Assign care coordinators for follow-up
```

#### Workflow 2: Pneumonia Triage
```
1. Radiologist uploads chest X-ray
2. Model returns 92% pneumonia probability
3. Grad-CAM shows consolidation in right lung
4. Radiologist confirms diagnosis + prioritizes treatment
```

---

## üìÅ Folder Structure

```
HealthCare System/
‚îÇ
‚îú‚îÄ‚îÄ README.md                           ‚Üê This file
‚îú‚îÄ‚îÄ PREPROCESSING_GUIDE.md              ‚Üê Detailed preprocessing documentation
‚îú‚îÄ‚îÄ DASHBOARD_EXPLANATION_GUIDE.md      ‚Üê Evaluator presentation guide
‚îú‚îÄ‚îÄ requirements.txt                    ‚Üê Python dependencies
‚îú‚îÄ‚îÄ LICENSE                             ‚Üê MIT License
‚îÇ
‚îú‚îÄ‚îÄ Data/                               ‚Üê Datasets (not tracked in Git)
‚îÇ   ‚îú‚îÄ‚îÄ Raw/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ diabetic_data.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ human_vital_signs_dataset_2024.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pneumoniamnist.npz
‚îÇ   ‚îî‚îÄ‚îÄ Processed/
‚îÇ       ‚îú‚îÄ‚îÄ diabetic_data_cleaned.csv
‚îÇ       ‚îú‚îÄ‚îÄ cleaned_vital_dataset.csv
‚îÇ       ‚îú‚îÄ‚îÄ cleaned_feedback_dataset.csv
‚îÇ       ‚îî‚îÄ‚îÄ pneumoniamnist_balanced.npz
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                          ‚Üê Jupyter notebooks
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing_version_1.ipynb   ‚Üê Tabular data preprocessing (4 models)
‚îÇ   ‚îú‚îÄ‚îÄ Preprocessing.ipynb             ‚Üê Time-series preprocessing (LSTM)
‚îÇ   ‚îú‚îÄ‚îÄ classification_version_1.ipynb  ‚Üê Readmission model training
‚îÇ   ‚îú‚îÄ‚îÄ regression_version_1.ipynb      ‚Üê LOS model training
‚îÇ   ‚îú‚îÄ‚îÄ clustering_version_1.ipynb      ‚Üê KMeans clustering
‚îÇ   ‚îú‚îÄ‚îÄ Association_version_1.ipynb     ‚Üê Association rule mining
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ Dashboard/                      ‚Üê Streamlit application
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.py                      ‚Üê Main dashboard (multi-dataset homepage)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pages/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ 1_readmission_model.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ 2_los_prediction.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ 3_clustering.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ 4_Sentiment_Analysis.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ 5_Association_Rules.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ 6_x-ray_diagostics.py
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ 7_LSTM_Risk_Prediction.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ Models/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sentiment_model.py          ‚Üê BERT prediction backend
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ deep learning/
‚îÇ       ‚îú‚îÄ‚îÄ bert_sentiment/
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ checkpoint-135/         ‚Üê Fine-tuned BERT model
‚îÇ       ‚îî‚îÄ‚îÄ cnn_pneumonia/
‚îÇ           ‚îî‚îÄ‚îÄ resnet50_model.h5       ‚Üê Trained CNN weights
‚îÇ
‚îú‚îÄ‚îÄ Trained_Models/                     ‚Üê Saved model artifacts
‚îÇ   ‚îú‚îÄ‚îÄ Readmission/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ xgb_readmission_final.pkl
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scaler_readmission_final.pkl
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ selected_features_final.pkl
‚îÇ   ‚îú‚îÄ‚îÄ LOS_Prediction/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ xgb_los_final.pkl
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scaler_los_final.pkl
‚îÇ   ‚îú‚îÄ‚îÄ Clustering/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ kmeans_model.pkl
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scaler_clustering.pkl
‚îÇ   ‚îú‚îÄ‚îÄ Sentiment/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ checkpoint-135/
‚îÇ   ‚îî‚îÄ‚îÄ CNN/
‚îÇ       ‚îî‚îÄ‚îÄ pneumonia_cnn.h5
‚îÇ
‚îú‚îÄ‚îÄ mlartifacts/                        ‚Üê MLflow experiment tracking
‚îÇ   ‚îî‚îÄ‚îÄ 1/                              ‚Üê Experiment runs
‚îÇ
‚îî‚îÄ‚îÄ outputs/                            ‚Üê Generated reports
    ‚îú‚îÄ‚îÄ classification_report_rf.txt
    ‚îú‚îÄ‚îÄ regression_report.txt
    ‚îî‚îÄ‚îÄ top_association_rules.csv
```

### Key Directories Explained

- **`notebooks/Dashboard/`**: All Streamlit dashboard code (homepage + 7 model pages)
- **`Trained_Models/`**: Serialized models, scalers, encoders for production use
- **`Data/Processed/`**: Cleaned datasets ready for model inference
- **`mlartifacts/`**: MLflow tracking for hyperparameter tuning experiments
- **`notebooks/deep learning/`**: BERT and CNN training notebooks + model checkpoints

---

## üìä Model Performance

### Classification Models

| Model | Dataset | Accuracy | Precision | Recall | F1-Score | AUC-ROC |
|-------|---------|----------|-----------|--------|----------|---------|
| **XGBoost (Readmission)** | Diabetic (101K) | 67% | 0.35 | 0.68 | 0.46 | 0.72 |
| **LSTM (ICU Risk)** | Vital Signs | 89% | 0.87 | 0.91 | 0.89 | 0.93 |
| **BERT (Sentiment)** | Feedback | 92% | 0.91 | 0.93 | 0.91 | 0.95 |
| **ResNet50 (Pneumonia)** | X-Ray (8K) | 94% | 0.93 | 0.96 | 0.94 | 0.97 |

### Regression Model

| Model | Dataset | MAE (days) | RMSE (days) | R¬≤ Score | MAPE |
|-------|---------|------------|-------------|----------|------|
| **XGBoost (LOS)** | Diabetic | 1.05 | 1.51 | 0.78 | 18.2% |

### Clustering Model

| Model | Dataset | Silhouette Score | Davies-Bouldin | Optimal Clusters |
|-------|---------|------------------|----------------|------------------|
| **KMeans** | Diabetic | 0.42 | 1.28 | k=4 |

### Association Rules

| Metric | Value |
|--------|-------|
| Total Rules Generated | 1,247 |
| Top Rule Confidence | 0.89 |
| Average Lift | 2.34 |
| Min Support Threshold | 0.01 (1%) |

### Performance Notes
- **Readmission Model:** Lower metrics due to severe class imbalance (11% positive class). SMOTE improved recall from 0.45 to 0.68.
- **LSTM Model:** Best performance when using bidirectional architecture + attention mechanism.
- **BERT Model:** Fine-tuning for 5 epochs optimal (validation loss plateaued after epoch 4).
- **CNN Model:** Transfer learning essential (training from scratch achieved only 78% accuracy).

---

## ‚ö†Ô∏è Limitations & Next Steps

### Current Limitations

#### 1. Data Limitations
- **Small Image Dataset:** 8,136 X-rays insufficient for production-grade diagnosis (need 100K+ images)
- **Class Imbalance:** Readmission dataset has only 11% positive cases (despite SMOTE, model favors majority class)
- **Temporal Gaps:** Vital signs dataset missing continuous monitoring data (only 10-minute snapshots)
- **Text Corpus Size:** 5,000 feedback samples too small for robust BERT fine-tuning (recommend 50K+)

#### 2. Model Limitations
- **Readmission Model:** 67% accuracy below clinical threshold (need 80%+ for deployment)
- **No Explainability:** XGBoost provides feature importance but lacks SHAP values for individual predictions
- **Static Models:** No continuous learning pipeline (models degrade as patient population shifts)
- **Single-Disease Focus:** Pneumonia detection only; need multi-disease chest X-ray classifier

#### 3. Technical Limitations
- **No API:** Dashboard requires manual input; lacks RESTful API for EHR integration
- **Local Deployment Only:** Not containerized (Docker) or cloud-ready (AWS SageMaker)
- **Limited Scalability:** Streamlit struggles with >1000 concurrent users
- **No User Authentication:** All users share same session; no role-based access control

#### 4. Clinical Validation
- **Not FDA-Approved:** Models lack regulatory clearance for clinical use
- **No Prospective Testing:** Evaluated on historical data only (not tested on live patient outcomes)
- **Missing Clinical Workflow Integration:** Predictions not linked to EHR alert systems

### Next Steps (Roadmap)

#### Phase 1: Model Improvements (Q2 2026)
- [ ] **Expand Datasets**
  - Collect 50K+ chest X-rays from multiple hospitals (address distribution shift)
  - Partner with EHR vendors for 500K+ patient records
  - Augment feedback dataset with NLP annotation tools

- [ ] **Enhance Readmission Model**
  - Test ensemble methods (XGBoost + LightGBM + CatBoost voting classifier)
  - Add SHAP explainability for interpretable predictions
  - Incorporate social determinants of health (SDOH) features

- [ ] **Multi-Task Learning**
  - Train single CNN for pneumonia + tuberculosis + COVID-19 detection
  - Joint LSTM model for ICU risk + ventilator weaning prediction

#### Phase 2: Production Readiness (Q3 2026)
- [ ] **API Development**
  - Build FastAPI REST endpoints for each model
  - Add authentication (OAuth 2.0) and rate limiting
  - Create Swagger documentation

- [ ] **Containerization**
  - Dockerize all models (separate containers per service)
  - Set up Kubernetes orchestration for auto-scaling
  - Implement CI/CD pipeline with GitHub Actions

- [ ] **Cloud Deployment**
  - Migrate to AWS SageMaker for model hosting
  - Use S3 for dataset storage, RDS for user data
  - Set up CloudWatch monitoring and alerting

#### Phase 3: Clinical Integration (Q4 2026)
- [ ] **EHR Integration**
  - Develop HL7 FHIR connectors for Epic/Cerner
  - Embed predictions directly in clinician workflow
  - Auto-populate risk scores in patient charts

- [ ] **Prospective Validation**
  - Conduct IRB-approved pilot study at partner hospital
  - Compare model predictions vs. actual outcomes (30-day follow-up)
  - Publish results in peer-reviewed journal

- [ ] **Regulatory Compliance**
  - Prepare FDA 510(k) submission for pneumonia detection
  - Achieve HIPAA compliance (data encryption, audit logs)
  - Conduct bias/fairness audit across demographic groups

#### Phase 4: Advanced Features (2027)
- [ ] **Continuous Learning**
  - Implement active learning loop (retrain on misclassified cases)
  - A/B test model versions in production
  - Set up MLflow model registry for version control

- [ ] **Explainable AI**
  - Add LIME for text sentiment explanations
  - Implement Grad-CAM++ for better X-ray heatmaps
  - Create natural language explanations ("High risk because...")

- [ ] **Federated Learning**
  - Train models across multiple hospitals without sharing raw data
  - Preserve patient privacy while improving generalization
  - Partner with 5+ healthcare systems

### Immediate Priority (Next 30 Days)
1. ‚úÖ **Collect more readmission data** (target: double dataset size)
2. ‚úÖ **Add SHAP explainability** to XGBoost models
3. ‚úÖ **Containerize dashboard** with Docker
4. ‚úÖ **Write unit tests** for preprocessing pipelines (pytest)
5. ‚úÖ **Document API specifications** for future development

---

## üõ†Ô∏è Technologies Used

### Machine Learning Frameworks
- **XGBoost 2.0.0:** Gradient boosting for tabular data (classification + regression)
- **Scikit-Learn 1.3.0:** Preprocessing, KMeans clustering, evaluation metrics
- **TensorFlow 2.13.0:** LSTM and CNN deep learning models
- **PyTorch 2.0.1:** BERT model backend (via Transformers library)

### Deep Learning Libraries
- **Transformers 4.33.0:** Hugging Face library for DistilBERT fine-tuning
- **Keras (TensorFlow):** High-level API for ResNet50 training

### Data Science Stack
- **Pandas 2.0.3:** Data manipulation and analysis
- **NumPy 1.24.3:** Numerical computing
- **MLxtend 0.22.0:** Association rule mining (Apriori algorithm)

### Visualization
- **Plotly 5.17.0:** Interactive charts (bar, pie, histogram, scatter)
- **Matplotlib 3.7.2:** Static plots for notebooks
- **Seaborn 0.12.2:** Statistical visualizations

### Web Framework
- **Streamlit 1.28.0:** Dashboard interface with caching and widgets

### Utilities
- **Pillow 10.0.0:** Image processing for X-ray uploads
- **Joblib 1.3.2:** Model serialization (pickle alternative)
- **MLflow 2.5.0:** Experiment tracking and hyperparameter logging

### Development Tools
- **Jupyter Notebook:** Interactive development environment
- **Git/GitHub:** Version control
- **VSCode:** Primary IDE

---

## ü§ù Contributing

We welcome contributions! Here's how you can help:

### How to Contribute
1. **Fork the repository**
2. **Create a feature branch** (`git checkout -b feature/AmazingFeature`)
3. **Commit your changes** (`git commit -m 'Add some AmazingFeature'`)
4. **Push to the branch** (`git push origin feature/AmazingFeature`)
5. **Open a Pull Request**

### Contribution Guidelines
- Follow PEP 8 style guide for Python code
- Add docstrings to all functions (Google-style format)
- Write unit tests for new features (pytest)
- Update README.md if adding new models or datasets
- Include performance metrics for model improvements

### Areas for Contribution
- üêõ **Bug Fixes:** Report or fix issues in the [Issues](https://github.com/yourusername/healthcare-ai-dashboard/issues) tab
- üìä **New Models:** Add additional AI models (e.g., stroke prediction, sepsis detection)
- üé® **UI Improvements:** Enhance dashboard design with custom CSS
- üìñ **Documentation:** Improve code comments, add tutorials, translate README

---

## üìÑ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

### Key Points
- ‚úÖ Free to use, modify, and distribute
- ‚úÖ Commercial use allowed
- ‚ö†Ô∏è Must include original copyright notice
- ‚ö†Ô∏è No warranty provided (use at your own risk)

**Disclaimer:** This software is for **research and educational purposes only**. It is **NOT FDA-approved** and should **NOT** be used for clinical decision-making without proper validation and regulatory clearance.

---

## üìû Contact & Support

**Project Maintainer:** [Your Name]  
**Email:** your.email@example.com  
**LinkedIn:** [Your LinkedIn Profile]  
**GitHub Issues:** [Report Bugs Here](https://github.com/yourusername/healthcare-ai-dashboard/issues)

### Getting Help
- üìñ Check the [PREPROCESSING_GUIDE.md](PREPROCESSING_GUIDE.md) for data pipeline questions
- üéØ Review [DASHBOARD_EXPLANATION_GUIDE.md](DASHBOARD_EXPLANATION_GUIDE.md) for evaluator presentation tips
- üí¨ Open a GitHub issue for bug reports or feature requests
- üìß Email for collaboration or research inquiries

---

## üôè Acknowledgments

- **Datasets:** UCI Machine Learning Repository, MedMNIST project
- **Pre-trained Models:** Hugging Face (DistilBERT), Keras Applications (ResNet50)
- **Inspiration:** Dr. Andrew Ng's Healthcare AI course, Fast.ai community
- **Libraries:** Open-source contributors of Streamlit, XGBoost, TensorFlow

---

## üìà Project Statistics

- **Total Code Lines:** ~8,500 (excluding comments)
- **Models Trained:** 7
- **Datasets Processed:** 4 (115K+ total records, 8K+ images)
- **Dashboard Pages:** 8 (1 homepage + 7 model pages)
- **Dependencies:** 20+ Python packages
- **Development Time:** 6 weeks
- **Training Compute:** ~40 GPU hours (Google Colab T4)

---

<div align="center">

**‚≠ê If this project helped you, please give it a star! ‚≠ê**

**Built with ‚ù§Ô∏è for improving healthcare outcomes through AI**

[üîù Back to Top](#-healthcare-ai-dashboard---multi-model-predictive-analytics-system)

</div>
