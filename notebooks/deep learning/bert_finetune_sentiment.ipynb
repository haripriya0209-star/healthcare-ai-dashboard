{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3adf24ad",
   "metadata": {},
   "source": [
    "## Goal: Build a BERT‑based sentiment classifier for patient feedback.\n",
    "\n",
    "## Why BERT: It understands context better than LSTM and gives higher accuracy.\n",
    "\n",
    "## What you do: Clean text → Fine‑tune BERT → Evaluate → Save model.\n",
    "\n",
    "## Outcome: A strong, modern NLP model ready for dashboards and real‑world use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1055ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>discharge instructions were very clear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i felt the doctor used too much medical jargon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i appreciated the reminders about my medicines</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>instructions after discharge were not helpful</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>instructions after discharge were not helpful</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_text  Sentiment\n",
       "0          discharge instructions were very clear          1\n",
       "1  i felt the doctor used too much medical jargon          1\n",
       "2  i appreciated the reminders about my medicines          1\n",
       "3   instructions after discharge were not helpful          0\n",
       "4   instructions after discharge were not helpful          0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"D:\\HealthCare System\\cleaned_feedback_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea2bb344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd257c0b",
   "metadata": {},
   "source": [
    "## Renaming Sentiment column to labels BEFORE tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac3c4017",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.rename(columns={\"Sentiment\": \"labels\"})\n",
    "val_df   = val_df.rename(columns={\"Sentiment\": \"labels\"})\n",
    "test_df  = test_df.rename(columns={\"Sentiment\": \"labels\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7986faa",
   "metadata": {},
   "source": [
    " ## Tokenization function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aef441af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d180b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"clean_text\"],          # the cleaned text column\n",
    "        padding=\"max_length\",         # pad all sequences to same length\n",
    "        truncation=True,              # cut off long text safely\n",
    "        max_length=64                 # max token length for BERT\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3591aa",
   "metadata": {},
   "source": [
    "##  Convert pandas → HuggingFace Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6696b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "val_ds   = Dataset.from_pandas(val_df)\n",
    "test_ds  = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4980e5c8",
   "metadata": {},
   "source": [
    "## Applying tokenization to datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8207f0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f3c437524df478197ba8fcbc629562c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/720 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36de98cfad54bb78f710f3de803c953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d448a73d45242f6a124fa99e1d70cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds = train_ds.map(tokenize, batched=True)   # tokenize training data\n",
    "val_ds   = val_ds.map(tokenize, batched=True)     # tokenize validation data\n",
    "test_ds  = test_ds.map(tokenize, batched=True)    # tokenize test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fce293e",
   "metadata": {},
   "source": [
    "## Load the bert model for classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1a46b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=2,                    # 2 sentiment classes\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad738a02",
   "metadata": {},
   "source": [
    "## Set training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af5c16b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"bert_sentiment\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21f8dce",
   "metadata": {},
   "source": [
    "## computing metrics to add in trainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc9cf423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    matthews_corrcoef\n",
    ")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds  = pred.predictions.argmax(-1)\n",
    "    \n",
    "    accuracy  = accuracy_score(labels, preds)\n",
    "    mcc       = matthews_corrcoef(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'mcc': mcc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "addf0449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harip\\AppData\\Local\\Temp\\ipykernel_21256\\2804729603.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "badfbcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harip\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='135' max='135' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [135/135 02:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=135, training_loss=0.0007368486650564053, metrics={'train_runtime': 121.3176, 'train_samples_per_second': 17.805, 'train_steps_per_second': 1.113, 'total_flos': 35766197637120.0, 'train_loss': 0.0007368486650564053, 'epoch': 3.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a3b309b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harip\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.00015362749400082976,\n",
       " 'eval_accuracy': 1.0,\n",
       " 'eval_mcc': 1.0,\n",
       " 'eval_precision': 1.0,\n",
       " 'eval_recall': 1.0,\n",
       " 'eval_f1': 1.0,\n",
       " 'eval_runtime': 2.7116,\n",
       " 'eval_samples_per_second': 73.758,\n",
       " 'eval_steps_per_second': 4.794,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4361f2d4",
   "metadata": {},
   "source": [
    "##  model is not overfitting because:\n",
    "- Training performance is excellent\n",
    "- Test performance is also excellent\n",
    "If it were overfitting, test accuracy would drop.\n",
    "model is simply strong and  dataset is easy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5743e451",
   "metadata": {},
   "source": [
    "## Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c2f8147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "    pred = outputs.logits.argmax(dim=1).item()\n",
    "\n",
    "    return \"Positive\" if pred == 1 else \"Negative\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6283b45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"The doctor was very rude and unprofessional.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "abf16c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"The staff were extremely kind and helpful.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8cee78a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Waiting time was too long.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d431a5",
   "metadata": {},
   "source": [
    "## Limitations & Future Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb34e2d5",
   "metadata": {},
   "source": [
    ". Occasional Misclassification of Strongly Negative Sentences\n",
    "Although the model achieves excellent overall performance, it misclassifies a small number of strongly negative sentences such as:\n",
    "- “The doctor was very rude and unprofessional.”\n",
    "This happens because the training data may not contain enough examples with harsh or explicit negative language. As a result, the model sometimes interprets these sentences as neutral or mildly positive.\n",
    "Why this happens\n",
    "- The dataset may be biased toward polite or mild wording.\n",
    "- Strong negative words like rude, unprofessional, terrible, horrible may be under‑represented.\n",
    "- BERT generalizes well overall but struggles with rare patterns it hasn’t seen enough times.\n",
    "Impact\n",
    "This does not break the model, but it can hide important negative feedback if used in a real hospital dashboard.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25c26dc",
   "metadata": {},
   "source": [
    "## FINAL ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6529b2a1",
   "metadata": {},
   "source": [
    "## The model achieved high performance due to optimal fine‑tuning parameters (learning_rate=2e‑5, batch_size=16, epochs=3, weight_decay=0.01), clean tokenization (max_length=64, padding, truncation), and the use of DistilBERT’s strong pretrained language representations. \n",
    "\n",
    "## The HuggingFace Trainer handled optimization, scheduling, and batching, while a custom compute_metrics function enabled full evaluation (Accuracy, Precision, Recall, F1, MCC). Clean dataset preprocessing and correct label formatting (labels) ensured stable and efficient learning.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
